{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a97aa9-bb08-4166-b03a-304df629b0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_even_odd():\n",
    "    try:\n",
    "        num = int(input(\"Enter a number: \"))\n",
    "        if num % 2 == 0:\n",
    "            print(f\"{num} is an even number.\")\n",
    "        else:\n",
    "            print(f\"{num} is an odd number.\")\n",
    "    except ValueError:\n",
    "        print(\"Invalid input! Please enter a valid number.\")\n",
    "\n",
    "#Call the function\n",
    "check_even_odd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b1ff57b-cff0-411f-8813-4d8794bf26fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#Step 1: Generate a random number\n",
    "secret_number = random.randint(1, 10)\n",
    "\n",
    "#Step 2: Game loop\n",
    "while True:\n",
    "    guess = int(input(\"Guess a number (1-10): \"))\n",
    "\n",
    "    if guess < secret_number:\n",
    "        print(\"Too low, try again!\")\n",
    "    elif guess > secret_number:\n",
    "        print(\"Too high, try again!\")\n",
    "    else:\n",
    "        print(\"Congratulations! You guessed it!\")\n",
    "        break   #Exit loop when guessed correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73a44502-bcd7-4c6e-ab86-1ccb7718cc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prime Number Checker\n",
    "num = int(input(\"Enter a number: \"))\n",
    "\n",
    "if num > 1:\n",
    "    for i in range(2, num):\n",
    "        if num % i == 0:\n",
    "            print(f\"{num} is not a prime number.\")\n",
    "            break\n",
    "    else:\n",
    "        print(f\"{num} is a prime number.\")\n",
    "else:\n",
    "    print(f\"{num} is not a prime number.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edfeb5d7-4093-4e1e-8589-e6dc2798eff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fibonacci Sequence\n",
    "def fibonacci(n):\n",
    "    a, b = 0, 1\n",
    "    while a < n:\n",
    "        print(a, end=' ')\n",
    "        a, b = b, a + b\n",
    "\n",
    "num = int(input(\"Enter the upper limit for the Fibonacci sequence: \"))\n",
    "fibonacci(num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ff26a28-2354-4f99-8c3b-485e79da3061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factorial Calculation\n",
    "def factorial(n):\n",
    "    if n == 0 or n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return n * factorial(n - 1)\n",
    "\n",
    "num = int(input(\"Enter a number to find its factorial: \"))\n",
    "print(f\"Factorial of {num} is {factorial(num)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08c4daf0-294d-4c3e-8be5-b1be957dd8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armstrong Number Checker\n",
    "num = int(input(\"Enter a number: \"))\n",
    "num_str = str(num)\n",
    "num_digits = len(num_str)\n",
    "\n",
    "# Calculate the sum of digits raised to the power of the number of digits\n",
    "sum_of_powers = sum(int(digit) ** num_digits for digit in num_str)\n",
    "\n",
    "if sum_of_powers == num:\n",
    "    print(f\"{num} is an Armstrong number.\")\n",
    "else:\n",
    "    print(f\"{num} is not an Armstrong number.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f71c779-4219-4c44-8ae9-567350c46569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armstrong Numbers in a Range\n",
    "lower = int(input(\"Enter the lower limit: \"))\n",
    "upper = int(input(\"Enter the upper limit: \"))\n",
    "\n",
    "print(f\"Armstrong numbers between {lower} and {upper} are:\")\n",
    "for num in range(lower, upper + 1):\n",
    "    num_str = str(num)\n",
    "    num_digits = len(num_str)\n",
    "    sum_of_powers = sum(int(digit) ** num_digits for digit in num_str)\n",
    "    \n",
    "    if sum_of_powers == num:\n",
    "        print(num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e946aa4-a4a5-42d7-b0d2-9937052292fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmath  # For handling complex square roots\n",
    "\n",
    "# Coefficients a, b, c of the quadratic equation\n",
    "a = float(input(\"Enter coefficient a: \"))\n",
    "b = float(input(\"Enter coefficient b: \"))\n",
    "c = float(input(\"Enter coefficient c: \"))\n",
    "\n",
    "# Calculate the discriminant\n",
    "discriminant = b**2 - 4*a*c\n",
    "\n",
    "# Find two solutions using the quadratic formula\n",
    "root1 = (-b + cmath.sqrt(discriminant)) / (2 * a)\n",
    "root2 = (-b - cmath.sqrt(discriminant)) / (2 * a)\n",
    "\n",
    "print(f\"The roots of the quadratic equation are: {root1} and {root2}\")\n",
    "\n",
    "# Check the nature of the roots\n",
    "if discriminant > 0:\n",
    "    print(f\"The roots are real and distinct: {root1} and {root2}\")\n",
    "elif discriminant == 0:\n",
    "    print(f\"The roots are real and equal: {root1}\")\n",
    "else:\n",
    "    print(f\"The roots are complex: {root1} and {root2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9ecf4ad-beba-4ade-beb3-e42147acb7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find factors of a number\n",
    "num = int(input(\"Enter a number: \"))\n",
    "factors = []\n",
    "\n",
    "# Loop through numbers from 1 to the entered number\n",
    "for i in range(1, num + 1):\n",
    "    if num % i == 0:\n",
    "        factors.append(i)\n",
    "\n",
    "print(f\"The factors of {num} are: {factors}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df6870c8-2497-470c-9d98-00648512246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integer data type\n",
    "integer_example = 10\n",
    "print(\"Value:\", integer_example, \"Type:\", type(integer_example))\n",
    "\n",
    "# Float data type\n",
    "float_example = 10.5\n",
    "print(\"Value:\", float_example, \"Type:\", type(float_example))\n",
    "\n",
    "# String data type\n",
    "string_example = \"Hello, Python!\"\n",
    "print(\"Value:\", string_example, \"Type:\", type(string_example))\n",
    "\n",
    "# Boolean data type\n",
    "boolean_example = True\n",
    "print(\"Value:\", boolean_example, \"Type:\", type(boolean_example))\n",
    "\n",
    "# List data type\n",
    "list_example = [1, 2, 3, 4, 5]\n",
    "print(\"Value:\", list_example, \"Type:\", type(list_example))\n",
    "\n",
    "# Tuple data type\n",
    "tuple_example = (1, 2, 3, 4, 5)\n",
    "print(\"Value:\", tuple_example, \"Type:\", type(tuple_example))\n",
    "\n",
    "# Set data type\n",
    "set_example = {1, 2, 3, 4, 5}\n",
    "print(\"Value:\", set_example, \"Type:\", type(set_example))\n",
    "\n",
    "# Dictionary data type\n",
    "dict_example = {'name': 'Alice', 'age': 25, 'city': 'New York'}\n",
    "print(\"Value:\", dict_example, \"Type:\", type(dict_example))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ed2d6ec-d941-48a2-86fa-eb522791fbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, ValidationError\n",
    "import json\n",
    "\n",
    "# Define Pydantic schema\n",
    "class Book(BaseModel):\n",
    "    title: str\n",
    "    author: str\n",
    "    year_published: int\n",
    "    genres: list[str]\n",
    "\n",
    "# AI's JSON response (in practice, replace this with the actual AI output)\n",
    "ai_response = '''\n",
    "{\n",
    "  \"title\": \"To Kill a Mockingbird\",\n",
    "  \"author\": \"Harper Lee\",\n",
    "  \"year_published\": 1960,\n",
    "  \"genres\": [\"Southern Gothic\", \"Coming-of-Age\"]\n",
    "}\n",
    "'''\n",
    "\n",
    "# Validate JSON response\n",
    "try:\n",
    "    book_data = json.loads(ai_response)\n",
    "    book = Book(**book_data)\n",
    "    print(\"Valid JSON:\", book.json())\n",
    "except ValidationError as e:\n",
    "    print(\"Validation Error:\", e)\n",
    "except json.JSONDecodeError as e:\n",
    "    print(\"Invalid JSON format:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70217455-c3a5-4820-bb91-d1fdf22eb488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_and_format_response(response):\n",
    "    # Remove unwanted characters or extra text, including tildes\n",
    "    cleaned_response = re.sub(r'[^{}:,\\\\\"\\[\\]0-9a-zA-Z\\s-]', '', response)\n",
    "    \n",
    "    # Further process the cleaned response to remove extra spaces within words\n",
    "    formatted_response = re.sub(r'\\s+', ' ', cleaned_response).strip()\n",
    "    \n",
    "    # Fix space issues within JSON keys and values\n",
    "    formatted_response = re.sub(r'\\\" \\s*([^\\\"]*?)\\s* \\\"\\s*:', r'\"\\1\":', formatted_response)\n",
    "    formatted_response = re.sub(r':\\s*\\\" \\s*([^\\\"]*?)\\s* \\\"', r':\"\\1\"', formatted_response)\n",
    "    formatted_response = re.sub(r'\\\" \\s*([^\\\"]*?)\\s* \\\":', r'\"\\1\":', formatted_response)\n",
    "    \n",
    "    # Handle internal word splits\n",
    "    formatted_response = re.sub(r'([a-zA-Z])\\s+([a-zA-Z])', r'\\1\\2', formatted_response)\n",
    "    \n",
    "    return formatted_response\n",
    "\n",
    "# Example usage\n",
    "response = \"\"\"\n",
    "{\n",
    "    \"data\": {\n",
    "        \" status \": \" success \",\n",
    "        \" total tasks \": 6,\n",
    "        \" tasks \": [\n",
    "            {\n",
    "                \" task title \": \" Develop a custom dashboard for analyzing sales data using Power BI \",\n",
    "                \" scenario \": \" An organization is looking to improve their sales analytics with a new BI solution. They need a customized dashboard that can handle large datasets and provide actionable insights.\",\n",
    "                \" objective \": \" Develop ing an interactive dashboard for analyzing sales data \",\n",
    "                \" task description \": \" Design and develop a custom dashboard in Power BI using SQL for database querying and manipulation, including data visualization, filtering, and sorting capabilities.\",\n",
    "                \" resources \": [\" Power BI, SQL \"],\n",
    "                \" estimated time \": 60,\n",
    "                \" evaluation criteria \": [\n",
    "                    {\n",
    "                        \" c riterion \": \" Technical Execution \",\n",
    "                        \" weight age \": 50\n",
    "                    },\n",
    "                    {\n",
    "                        \" c riterion \": \" Problem -S olving \",\n",
    "                        \" weight age \": 30\n",
    "                    },\n",
    "                    {\n",
    "                        \" c riterion \": \" Communication \",\n",
    "                        \" weight age \": 20\n",
    "                    }\n",
    "                ],\n",
    "                \" follow up questions \": [\n",
    "                    \" What trade -offs did you consider in your approach? \",\n",
    "                    \" How would you communicate your solution to a non - technical stake holder? \"\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "cleaned_response = clean_and_format_response(response)\n",
    "print(cleaned_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a647584a-64b0-436f-9a85-f92b2c7954c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from enum import Enum\n",
    "\n",
    "from typing import Annotated\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic.config import ConfigDict\n",
    "\n",
    "\n",
    "class FooBar(BaseModel):\n",
    "    count: int\n",
    "    size: float | None = None\n",
    "\n",
    "\n",
    "class Gender(str, Enum):\n",
    "    male = 'male'\n",
    "    female = 'female'\n",
    "    other = 'other'\n",
    "    not_given = 'not_given'\n",
    "\n",
    "\n",
    "class MainModel(BaseModel):\n",
    "    \"\"\"\n",
    "    This is the description of the main model\n",
    "    \"\"\"\n",
    "\n",
    "    model_config = ConfigDict(title='Main')\n",
    "\n",
    "    foo_bar: FooBar\n",
    "    gender: Annotated[Gender | None, Field(alias='Gender')] = None\n",
    "    snap: int = Field(\n",
    "        default=42,\n",
    "        title='The Snap',\n",
    "        description='this is the value of snap',\n",
    "        gt=30,\n",
    "        lt=50,\n",
    "    )\n",
    "\n",
    "\n",
    "main_model_schema = MainModel.model_json_schema()  # (1)!\n",
    "print(json.dumps(main_model_schema, indent=2))  # (2)!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33262808-bbbd-4b40-9e68-f12c018e0607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"question\": \"What is Python?\",\n",
      "  \"options\": [\n",
      "    \"A programming language\",\n",
      "    \"A snake\",\n",
      "    \"A car brand\",\n",
      "    \"A movie\"\n",
      "  ],\n",
      "  \"answer\": \"A programming language\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from typing import List\n",
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "import json\n",
    "\n",
    "# Define the MCQ Pydantic model\n",
    "class MCQ(BaseModel):\n",
    "    question: str = Field(..., title=\"MCQ Question\")\n",
    "    options: List[str] = Field(..., title=\"Answer Choices\", min_items=2)\n",
    "    answer: str = Field(..., title=\"Correct Answer\")\n",
    "\n",
    "# Initialize Ollama LLM\n",
    "llm = Ollama(model=\"llama3.2:1b\")  # Ensure this model is available in `ollama list`\n",
    "\n",
    "# Define the parser\n",
    "parser = PydanticOutputParser(pydantic_object=MCQ)\n",
    "\n",
    "# Improved Prompt Template (Force Valid JSON output)\n",
    "prompt = PromptTemplate(\n",
    "    template=(\"\"\"\n",
    "    Generate a multiple-choice question on the following topic: {topic}\n",
    "\n",
    "    Instructions:\n",
    "    - Return a valid JSON object inside a Markdown code block.\n",
    "    - The JSON must follow this structure without additional text or formatting:\n",
    "    ```json\n",
    "    {{\n",
    "      \"question\": \"What is Python?\",\n",
    "      \"options\": [\"A programming language\", \"A snake\", \"A car brand\", \"A movie\"],\n",
    "      \"answer\": \"A programming language\"\n",
    "    }}\n",
    "    ```\n",
    "    âš ï¸ IMPORTANT: DO NOT include explanations, schema descriptions, or extra text.\n",
    "    \"\"\"),\n",
    "    input_variables=[\"topic\"]\n",
    ")\n",
    "\n",
    "# Function to generate MCQs\n",
    "def generate_mcq(topic: str):\n",
    "    formatted_prompt = prompt.format(topic=topic)\n",
    "    response = llm.invoke(formatted_prompt)\n",
    "\n",
    "    try:\n",
    "        # Extract JSON from response\n",
    "        start = response.find('```json')\n",
    "        end = response.rfind('```')\n",
    "        json_str = response[start+7:end].strip()\n",
    "\n",
    "        mcq = MCQ.model_validate_json(json_str)\n",
    "        \n",
    "        # Ensure answer is in options\n",
    "        if mcq.answer not in mcq.options:\n",
    "            raise ValueError(f\"âŒ Error: Answer '{mcq.answer}' is not in options {mcq.options}\")\n",
    "\n",
    "        return mcq\n",
    "    \n",
    "    except (ValidationError, ValueError) as e:\n",
    "        print(\"âš ï¸ Parsing Error:\", e)\n",
    "        print(\"ðŸ” Raw LLM Response:\", response)\n",
    "        return None\n",
    "\n",
    "# Example: Generate an MCQ on Java programming\n",
    "mcq = generate_mcq(\"Java programming\")\n",
    "if mcq:\n",
    "    print(mcq.model_dump_json(indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "712b0d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "message = AIMessage(content='\\`\\`\\`\\n{\"foo\": \"bar\"}\\n\\`\\`\\`')\n",
    "output_parser = JsonOutputParser()\n",
    "output_parser.invoke(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51f127b6-2116-4ef2-8c08-43118408d386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class MCQ(BaseModel):\n",
    "    question: str = Field(..., title=\"Question Text\")\n",
    "    options: List[str] = Field(..., title=\"Answer Choices\")\n",
    "    correct_answer: str = Field(..., title=\"Correct Answer\")\n",
    "    difficulty: str = Field(\n",
    "        ..., \n",
    "        title=\"Difficulty Level\", \n",
    "        pattern=\"^(easy|medium|hard)$\"  # âœ… Corrected\n",
    "    )\n",
    "\n",
    "# Example MCQ instance\n",
    "example_mcq = MCQ(\n",
    "    question=\"What is the capital of France?\",\n",
    "    options=[\"Berlin\", \"Madrid\", \"Paris\", \"Rome\"],\n",
    "    correct_answer=\"Paris\",\n",
    "    difficulty=\"easy\"\n",
    ")\n",
    "\n",
    "print(example_mcq.model_dump_json(indent=2))  # Pydantic v2 uses `model_dump_json()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ba69cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gemma3:1b'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from types import SimpleNamespace\n",
    "REQUIRED_MODELS = SimpleNamespace(\n",
    "    Gemma3Latest=\"gemma3\",\n",
    "    Qwen2_5_3b=\"qwen2.5:3b\",\n",
    "    DeepseekR1_1_5b=\"deepseek-r1:1.5b\",\n",
    "    Qwen2_5Latest=\"qwen2.5\",\n",
    "    DeepseekR1_7b=\"deepseek-r1:7b\",\n",
    "    Gemma3_1b=\"gemma3:1b\"\n",
    ")\n",
    "REQUIRED_MODELS.Gemma3_1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35e4f97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city='London' country='United Kingdom'\n",
      "Usage(requests=1, request_tokens=183, response_tokens=54, total_tokens=237, details=None)\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from pydantic import BaseModel\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "from pydantic_ai.providers.openai import OpenAIProvider\n",
    "\n",
    "\n",
    "class CityLocation(BaseModel):\n",
    "    city: str\n",
    "    country: str\n",
    "\n",
    "\n",
    "ollama_model = OpenAIModel(\n",
    "    model_name='granite3.2:2b', provider=OpenAIProvider(base_url='http://localhost:11434/v1')\n",
    ")\n",
    "agent = Agent(ollama_model, result_type=CityLocation)\n",
    "\n",
    "async def main():\n",
    "    result = await agent.run('Where were the olympics held in 2012?')\n",
    "    print(result.data)\n",
    "    print(result.usage())\n",
    "\n",
    "# Run the async function\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aa4f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic-ai in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (0.0.43)\n",
      "Requirement already satisfied: openai in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (1.68.2)\n",
      "Requirement already satisfied: ollama in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (0.4.7)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (0.29.3)\n",
      "Requirement already satisfied: flask-socketio in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (5.5.1)\n",
      "Requirement already satisfied: pydantic-ai-slim==0.0.43 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (0.0.43)\n",
      "Requirement already satisfied: eval-type-backport>=0.2.0 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from pydantic-ai-slim==0.0.43->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (0.2.2)\n",
      "Requirement already satisfied: griffe>=1.3.2 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from pydantic-ai-slim==0.0.43->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (1.6.2)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from pydantic-ai-slim==0.0.43->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (0.28.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.28.0 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from pydantic-ai-slim==0.0.43->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (1.31.1)\n",
      "Requirement already satisfied: pydantic-graph==0.0.43 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from pydantic-ai-slim==0.0.43->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (0.0.43)\n",
      "Requirement already satisfied: pydantic>=2.10 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from pydantic-ai-slim==0.0.43->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (2.10.6)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from pydantic-ai-slim==0.0.43->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (0.4.0)\n",
      "Requirement already satisfied: anthropic>=0.49.0 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (0.49.0)\n",
      "Requirement already satisfied: boto3>=1.34.116 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (1.37.18)\n",
      "Requirement already satisfied: argcomplete>=3.5.0 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (3.6.0)\n",
      "Requirement already satisfied: prompt-toolkit>=3 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (3.0.50)\n",
      "Requirement already satisfied: rich>=13 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (13.9.4)\n",
      "Requirement already satisfied: cohere>=5.13.11 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (5.14.0)\n",
      "Requirement already satisfied: groq>=0.15.0 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (0.20.0)\n",
      "Requirement already satisfied: mcp>=1.4.1 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (1.5.0)\n",
      "Requirement already satisfied: mistralai>=1.2.5 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (1.6.0)\n",
      "Requirement already satisfied: google-auth>=2.36.0 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (2.38.0)\n",
      "Requirement already satisfied: requests>=2.32.3 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (2.32.3)\n",
      "Requirement already satisfied: logfire-api>=1.2.0 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from pydantic-graph==0.0.43->pydantic-ai-slim==0.0.43->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (3.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from huggingface_hub) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from huggingface_hub) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: Flask>=0.9 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from flask-socketio) (3.1.0)\n",
      "Requirement already satisfied: python-socketio>=5.12.0 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from flask-socketio) (5.12.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from Flask>=0.9->flask-socketio) (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from Flask>=0.9->flask-socketio) (3.1.6)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from Flask>=0.9->flask-socketio) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from Flask>=0.9->flask-socketio) (8.1.8)\n",
      "Requirement already satisfied: blinker>=1.9 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from Flask>=0.9->flask-socketio) (1.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from httpx>=0.27->pydantic-ai-slim==0.0.43->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from httpx>=0.27->pydantic-ai-slim==0.0.43->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->pydantic-ai-slim==0.0.43->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from pydantic>=2.10->pydantic-ai-slim==0.0.43->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from pydantic>=2.10->pydantic-ai-slim==0.0.43->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (2.27.2)\n",
      "Requirement already satisfied: bidict>=0.21.0 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from python-socketio>=5.12.0->flask-socketio) (0.23.1)\n",
      "Requirement already satisfied: python-engineio>=4.11.0 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from python-socketio>=5.12.0->flask-socketio) (4.11.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from requests>=2.32.3->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from requests>=2.32.3->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (2.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: botocore<1.38.0,>=1.37.18 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from boto3>=1.34.116->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (1.37.18)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from boto3>=1.34.116->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from boto3>=1.34.116->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (0.11.4)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from cohere>=5.13.11->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (1.10.0)\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from cohere>=5.13.11->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (0.4.0)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from cohere>=5.13.11->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (0.21.1)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from cohere>=5.13.11->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (2.32.0.20250306)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from google-auth>=2.36.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from google-auth>=2.36.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from google-auth>=2.36.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (4.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from Jinja2>=3.1.2->Flask>=0.9->flask-socketio) (3.0.2)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from mcp>=1.4.1->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (2.8.1)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from mcp>=1.4.1->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (2.2.1)\n",
      "Requirement already satisfied: starlette>=0.27 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from mcp>=1.4.1->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (0.46.1)\n",
      "Requirement already satisfied: uvicorn>=0.23.1 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from mcp>=1.4.1->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (0.34.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from mistralai>=1.2.5->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (2.9.0.post0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from opentelemetry-api>=1.28.0->pydantic-ai-slim==0.0.43->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from opentelemetry-api>=1.28.0->pydantic-ai-slim==0.0.43->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (8.6.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from prompt-toolkit>=3->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (0.2.13)\n",
      "Requirement already satisfied: simple-websocket>=0.10.0 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from python-engineio>=4.11.0->python-socketio>=5.12.0->flask-socketio) (1.1.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from rich>=13->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from rich>=13->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (2.19.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.28.0->pydantic-ai-slim==0.0.43->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (1.17.2)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.28.0->pydantic-ai-slim==0.0.43->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=13->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.36.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from pydantic-settings>=2.5.2->mcp>=1.4.1->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (1.0.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from python-dateutil>=2.8.2->mistralai>=1.2.5->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai) (1.17.0)\n",
      "Requirement already satisfied: wsproto in c:\\users\\venka\\anaconda3\\envs\\intern\\lib\\site-packages (from simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio>=5.12.0->flask-socketio) (1.2.0)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Model' from 'pydantic_ai' (c:\\Users\\venka\\anaconda3\\envs\\Intern\\Lib\\site-packages\\pydantic_ai\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mflask_socketio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m emit\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel, Field, ValidationError\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic_ai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# âœ… Define the Pydantic Model for Structured JSON\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mSubModule\u001b[39;00m(BaseModel):\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'Model' from 'pydantic_ai' (c:\\Users\\venka\\anaconda3\\envs\\Intern\\Lib\\site-packages\\pydantic_ai\\__init__.py)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62efa01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Intern",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
